{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1132fd05",
   "metadata": {},
   "source": [
    "# MLP Example\n",
    "\n",
    "In this notebook, we will explore how to load a custom model, specifically a Multi-Layer Perceptron (MLP), using the configuration settings defined in our project.\n",
    "\n",
    "*Note: A bit of this notebook was inspired by [this tutorial](https://docs.pytorch.org/tutorials/beginner/introyt/trainingyt.html).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9aa8b",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f81ed32",
   "metadata": {},
   "source": [
    "### Load Local Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e03898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    return Path(\n",
    "        subprocess.check_output(\n",
    "            [\"git\", \"rev-parse\", \"--show-toplevel\"],\n",
    "            cwd=\".\",\n",
    "            stderr=subprocess.STDOUT,\n",
    "        )\n",
    "        .strip()\n",
    "        .decode()\n",
    "    )\n",
    "\n",
    "\n",
    "project_root = get_project_root()\n",
    "src_dir = project_root / \"src\"\n",
    "\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.append(str(src_dir))\n",
    "\n",
    "try:\n",
    "    from utils.seed_utils import set_seed\n",
    "except ImportError:\n",
    "    raise ImportError(\"Cannot import module. Make sure that the project is on the path\")\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f67dc",
   "metadata": {},
   "source": [
    "### Setup logs and config\n",
    "\n",
    "Here's the configuration used:\n",
    "\n",
    "```yaml\n",
    "logs:\n",
    "  _target_: schemas.log_schema.LogSchema\n",
    "  sink: ${path_config:run_log}\n",
    "  level: INFO\n",
    "  format: \"{time:YYYY-MM-DD HH:mm:ss.SSS} | {level} | {thread.name} | {name}:{function}:{line} - {message}\"\n",
    "  rotation: 10 MB\n",
    "  retention: 7 days\n",
    "  colorize: true\n",
    "\n",
    "model:\n",
    "  _target_: models.smol_lm3.smol_lm3_model.SmolLM3Model\n",
    "```\n",
    "\n",
    "But we want to use an MLP model instead:\n",
    "\n",
    "```yaml\n",
    "model:\n",
    "  _target_: models.mlp.mlp_model.MLPModel\n",
    "```\n",
    "\n",
    "So here we can override the model configuration when loading the settings, as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30fc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.app_config import AppConfig\n",
    "from utils.log_utils import setup_logs\n",
    "\n",
    "\n",
    "def setup(\n",
    "    config_dir: str | Path | None = None,\n",
    "    config_file: str = \"settings.yaml\",\n",
    "    overrides: list[str] | None = None,\n",
    "):\n",
    "    AppConfig.load(\n",
    "        config_dir=config_dir,\n",
    "        config_file=config_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "    setup_logs(config=AppConfig.settings[\"logs\"])\n",
    "\n",
    "\n",
    "setup(overrides=[\"model._target_=models.mlp.mlp_model.MLPModel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275df285",
   "metadata": {},
   "source": [
    "## Load MLP Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccec9883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 18:18:48.753\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1mMLP(\n",
      "  (model): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils.log_utils import log\n",
    "\n",
    "mlp = AppConfig.settings[\"model\"].model\n",
    "log(message=mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f19ddb",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4440d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from configs.path_config import path_config\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST(\n",
    "    path_config.data, train=True, transform=transform, download=True\n",
    ")\n",
    "validation_set = torchvision.datasets.FashionMNIST(\n",
    "    path_config.data, train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=4, shuffle=False\n",
    ")\n",
    "\n",
    "# Class labels\n",
    "classes = (\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle Boot\",\n",
    ")\n",
    "\n",
    "# Report split sizes\n",
    "print(\"Training set has {} instances\".format(len(training_set)))\n",
    "print(\"Validation set has {} instances\".format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4448c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-shirt/top  Trouser  T-shirt/top  Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085144a2",
   "metadata": {},
   "source": [
    "## Setup training MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e5c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "\n",
    "from configs.path_config import path_config\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 1e-3\n",
    "epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pin_memory = device.type == \"cuda\"\n",
    "num_workers = 2 if device.type == \"cuda\" else 0  # safe default for notebooks\n",
    "\n",
    "# Model\n",
    "model = mlp.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def run_epoch(model, loader, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(x)  # MLP has an internal Flatten\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    acc = total_correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "best_val_acc = 0.0\n",
    "save_dir = Path(path_config.models) / \"mlp_fashionmnist\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "checkpoint_path = save_dir / \"checkpoint.pth\"\n",
    "\n",
    "# Setup TensorBoard\n",
    "tensorboard_log_path = Path(path_config.tensorboard) / \"mlp_fashionmnist\"\n",
    "summary_writer = SummaryWriter(log_dir=tensorboard_log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb2c1d0",
   "metadata": {},
   "source": [
    "## Train MLP on FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91828ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmaubras/miniconda3/envs/pyenv/lib/python3.11/site-packages/tensorboard/data/server_ingester.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Training Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n",
      "\u001b[32m2025-10-07 18:19:16.756\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mEpoch 1/5 | train_loss=0.4938 acc=0.8194 | val_loss=0.4593 acc=0.8340\u001b[0m\n",
      "\u001b[32m2025-10-07 18:19:21.559\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m\tSaved new best (val_acc=0.8340)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 1/5 [00:26<01:45, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 18:19:43.163\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mEpoch 2/5 | train_loss=0.3963 acc=0.8547 | val_loss=0.4200 acc=0.8500\u001b[0m\n",
      "\u001b[32m2025-10-07 18:19:43.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m\tSaved new best (val_acc=0.8500)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 2/5 [00:48<01:10, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 18:20:05.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mEpoch 3/5 | train_loss=0.3668 acc=0.8649 | val_loss=0.4263 acc=0.8452\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  60%|██████    | 3/5 [01:10<00:46, 23.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 18:20:27.412\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mEpoch 4/5 | train_loss=0.3490 acc=0.8726 | val_loss=0.4304 acc=0.8489\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 4/5 [01:32<00:22, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 18:20:49.170\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mEpoch 5/5 | train_loss=0.3361 acc=0.8771 | val_loss=0.4082 acc=0.8612\u001b[0m\n",
      "\u001b[32m2025-10-07 18:20:49.176\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m\tSaved new best (val_acc=0.8612)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5/5 [01:54<00:00, 22.80s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from utils.tensorboard_utils import launch_tensorboard\n",
    "\n",
    "launch_tensorboard(log_dir=tensorboard_log_path)\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1), desc=\"Training Progress\"):\n",
    "    train_loss, train_acc = run_epoch(model, training_loader, optimizer)\n",
    "    val_loss, val_acc = run_epoch(model, validation_loader, optimizer=None)\n",
    "\n",
    "    log(\n",
    "        message=f\"Epoch {epoch}/{epochs} | train_loss={train_loss:.4f} acc={train_acc:.4f} | val_loss={val_loss:.4f} acc={val_acc:.4f}\"\n",
    "    )\n",
    "    summary_writer.add_scalars(\n",
    "        main_tag=\"accuracy\",\n",
    "        tag_scalar_dict={\"train\": train_acc, \"val\": val_acc},\n",
    "        global_step=epoch,\n",
    "    )\n",
    "    summary_writer.add_scalars(\n",
    "        main_tag=\"loss\",\n",
    "        tag_scalar_dict={\"train\": train_loss, \"val\": val_loss},\n",
    "        global_step=epoch,\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"config\": {\n",
    "                    **AppConfig.settings[\"model\"].config,\n",
    "                    \"seed\": SEED,\n",
    "                },\n",
    "            },\n",
    "            checkpoint_path,\n",
    "        )\n",
    "        log(\n",
    "            message=f\"\\tSaved new best (val_acc={best_val_acc:.4f})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129910ac",
   "metadata": {},
   "source": [
    "## Predict with loaded checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ed2ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 18:21:11.511\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[34m\u001b[1mGround truth: Ankle Boot, Pullover, Trouser, Trouser\u001b[0m\n",
      "\u001b[32m2025-10-07 18:21:11.513\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[34m\u001b[1mPredicted: Ankle Boot, Pullover, Trouser, Trouser\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loaded = AppConfig.settings[\"model\"].model.to(device)\n",
    "state = torch.load(checkpoint_path, map_location=device)\n",
    "loaded.load_state_dict(state[\"model_state_dict\"])\n",
    "\n",
    "dataiter = iter(validation_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "log(message=f\"Ground truth: {', '.join(classes[labels[j]] for j in range(4))}\")\n",
    "outputs = loaded(images)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "log(message=f\"Predicted: {', '.join(classes[preds[j]] for j in range(4))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb44114",
   "metadata": {},
   "source": [
    "## Here, the rest of your code. Enjoy !\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
